### **The content here is focusing on the following:**

* a) My recommended **7 + 1 steps** for Data Science and AI mentoring approach
* b) Quick **guideline points** / kind of a checklist of what to look for across various levels (Beginner, Intermediate etc.)
* c) Why do we need Data and AI - what are typical **business use cases** that we should get a feel of?
* d) **References** about some key areas


# Data Science and AI Mentoring Approach - My 7+1 steps
_(Step -2, -1, 0, 1, 2, 3, 4 and Infinity)_

### Objective
is to provide some thoughts, pointers around Data Science and AI for my mentees to get a direction. I get an opportunity to learn from them, my team and everyone that I interact and collaborate across around this theme.

### My Recommendation
Data Science is a journey and there are no short cuts around it like everything else where we want get into success. Let me also be very clear and request some of these key points to my mentees and whoever is reading this content. The content we need depends on the objectives that we would intend to pursue in life. The foundations and interpretations may vary depending on what we want to accomplish in a specific span - a Data Science Practitioner, Applied Data Scientist, Research Scientist and so on. Every role would expect us to get into different flavours of understanding and focus.

I would like to create an outline as an initial draft approach.

## (Step: -2): Pre-Requisites: Mindset 

* Mindset of Mathematics + Computer Science + Statistics + Programming + Story telling
* Mindset of Data Science Method/Approach to Success

Focus on a business problem and trying to understand business KPIs, drivers that are required as part of goal formulation and define strategy accordingly alligning to CRISP-DM methodology from an end to end Data Science perspective. Below diagram depicts a high level outline of the approach.

![plot of business problem solving using CRISP-DM](/figures/ProblemSolving_With_CRISPDM.png)

* [How to think like a Computer Scientist](https://runestone.academy/runestone/books/published/thinkcspy/index.html)

## (Step: -1) Fundamentals of Statistics, Linear Algebra, Programming

* [MIT Single Variable Calculus](https://www.youtube.com/watch?v=jbIQW0gkgxo&t=1s)
* [Khan Academy Calculus](https://www.khanacademy.org/math/calculus-1)
* [MIT Linear Algebra](https://www.youtube.com/watch?v=ZK3O402wf1c&list=PLE7DDD91010BC51F8)
* [Python Programming Basics](https://github.com/kkm24132/Mentoring_Enablement/tree/master/Python)
* [ISLR book and reference on Stats fundamentals](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)

## (Step:  0) DS/AI Ecosystem, Methodologies

* [Fundamentals of CRISP-DM Methodologies](https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining)

One must understand key aspects on CRISP-DM methodlogy, applications / use cases of Machine Learning. This repository focuses on some tutorials using open datasets. The Venn Diagram shows how specific dimensions are related.

![plot of chunk crisp-dm](/figures/crisp-dm.png)   ![plot of DS Venn Diagram](/figures/DS_VennDiagram.png)

CRISP-DM stands for Cross Industry Standard Process for Data Mining. It talks about various process phases / steps / lifecycle stages in a typical data science program.

- _Business Understanding_
- _Data Understanding_
- _Data Preparation_
- _Model Development_
- _Model Evaluation_
- _Deployment_

* Understanding where to spend 80% of effort in an end to end DS journey and where to spend 20% - 80-20 aspect that I call
* [Style guide for Python](https://www.python.org/dev/peps/pep-0008/)
* [Style guide for R](https://style.tidyverse.org/)
* [Reference for effective and professional data science coding](https://www.kaggle.com/rtatman/six-steps-to-more-professional-data-science-code)

Some of the following Data and AI Platforms can be considered for learning purposes, participating and collaborating in real-life projects or initiatives: 
- [Kaggle forum](www.Kaggle.com)
- [DS competitions to build a better world](https://www.drivendata.org/)
- [Enabling impact organizations to collaborate and work on a project to solutionize asap](https://omdena.com/)
- [Crowd Analytics collaboration](https://www.crowdanalytix.com/community)
- [Data camp to solve real world problems](https://learn.datacamp.com/projects)
- [InnoCentive - Open innovation and crowdsourcing company which primarily focuses on problems dealing with life sciences](https://www.innocentive.com/our-solvers/)
- [Codalab - Accelerating reproducible computational research](https://codalab.org/)

## (Step:  1) Machine Learning Fundamentals

 ![plot of ML Concepts](/figures/ML_Concepts.png)
 
 ![plot of ML Lifecycle](/figures/ML_Lifecycle.png)

All about Core Machine Learning - Supervised, Unsupervised, Reinforcement

* [Some key Feature Engg techniques](https://www.analyticsvidhya.com/blog/2020/10/7-feature-engineering-techniques-machine-learning/)
* [Model selection techniques with some visualization examples from Yellowbrick repo reference for learning](https://github.com/DistrictDataLabs/yellowbrick/tree/develop/examples)
* [Andrew Ng's course around ML](https://www.coursera.org/learn/machine-learning)
* [CognitiveClass.ai course - Data Science Foundations](https://cognitiveclass.ai/learn/data-science)
* [CognitiveClass.ai course - Applied DS with Python](https://cognitiveclass.ai/learn/data-science-with-python)
* [CognitiveClass.ai course - Applied DS with R](https://cognitiveclass.ai/learn/data-science-r)
* [Caltech CS156 ML course](http://work.caltech.edu/telecourse.html) 
* [Christopher Bishop's Pattern Recognition and ML Book](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)
* [Stanford Python Basics](https://cs231n.github.io/python-numpy-tutorial/)

## (Step:  2) Deep Learning Fundamentals

- deeplearning.ai from Andrew Ng
  - Watch DeepLearning.ai course lectures I, II, IV and V (2a)
  - Watch DeepLearning.ai course lecture III (2c)
  - Go through DeepLearning.ai assignments (2d)
- fast.ai from Jeremy Howard and R. Thomas
  - Go through fast.ai Part 1 (2b)
- Repeat steps 2a through 2d (2e)

Sequence of recommended learning could be 2a, 2b, 2c, 2d, 2e etc.

- [CNN for visual recognition - CS231n:Part1: Setting up the architecture](https://cs231n.github.io/neural-networks-1/)
- [CNN for visual recognition - CS231n:Part2: Setting up the data and loss](https://cs231n.github.io/neural-networks-2/)
- [CNN for visual recognition - CS231n:Part3: Learning and evaluation](https://cs231n.github.io/neural-networks-3/)

Other references on fundamentals:
- [Intro to deep learning and neural networks](https://www.analyticsvidhya.com/blog/2018/10/introduction-neural-networks-deep-learning/)
- [Improving neural networks with Hyper parameter tuning, Regularization and Others](https://www.analyticsvidhya.com/blog/2018/11/neural-networks-hyperparameter-tuning-regularization-deeplearning/)
- [CNN from scratch](https://www.analyticsvidhya.com/blog/2018/12/guide-convolutional-neural-network-cnn/)
- [Amazon ML University related Computer Vision GitHub reference](https://github.com/aws-samples/aws-machine-learning-university-accelerated-cv)


## (Step:  3) Delve into some depth around ML and DL

- Go in depth by having some interview experience and questions, references to prepare yourself for next level - [Preparation References](/Prep_Reference/ReadMe.md)
- Go through use cases and solve a use case 
- Use Kaggle and similar forums - [Check here for some top forums to hone your skills](/forums.md)
- Understand a framework and try to use it - PyTorch, Keras, Tensorflow
- [Write effective technical blogs](https://www.youtube.com/watch?v=YODPgBadj80)
- AutoML capability focus: for example, try to explore below libraries
  - auto-sklearn 
    - If your priority is a simple, clean interface and relatively quick results
    - Natural integration with sklearn
    - Works with commonly used models and methods
    - control over timing
  - TPOT (Tree based Pipeline Optimization Tool)
    - If priority is accuracy, with disregard for potentially long train times
    - Emphasis on advanced pre-processing methods
    - Outputs Python code for the best models
  - HyperOpt-sklearn
  - AutoKeras

## (Step:  4) Deep dive into ML and DL

* Applications and Use Cases leveraging CNN, RNN, LSTM
* Area wise use cases around - Forecasting, Classification, Clustering, Association etc.
* Research based thinking / analysis to solve novel problems / methods / approaches
* [Full stack Deep Learning - deploy AI solutions in real world](https://course.fullstackdeeplearning.com/)

## (Step: Infinity) Continuous Learning, Stay Current
This is all about continuous learning - what I refer as CD learning - Continuous Deep Learning. Sky is the limit. Keep yourself up to date and continue to learn. There is no end to it.

- ML Pipeline illustrative view using GCP

![plot of ML Pipeline sample using GCP](/figures/MLPipeline1_GCP.png)

- MLOps [MLOps Tooling Landscape](https://lnkd.in/g97vipX) 


# Business Use Cases by Industry (Illustrative)

Industry / Domain Area|Use Case Description
----------------------|--------------------
[BFSI / FinTech]<br>**Banking and Financial Services** <br>**Capital Markets** <br>**Insurance** | <ul><li> 1: Customer Segmentation, Customer Micro-Segmentation<li> 2: Risk Analytics and Regulation, Compliance<li> 3: Cross Selling and Up-selling<li> 4: Predictive Maintenance<li> 5: Customer Life Time Value Analysis<li>6: ESales and Marketing Campaign Management<li> 7: Evaluation of Credit Worthiness</ul>
[Retail and CPG]<br>**Retail** <br>**Consumer Packaged Goods** | <ul><li> 1: Predictive Inventory Planning, Predictive Maintenance<li> 2: Recommendation Engines<li> 3: Upsell and Cross Channel Marketing<li> 4: Market Segmentation and Targeting<li> 5: Market Basket Analysis with Association Rules<li>6: Customer ROI and Life time value analysis</ul>
[Healthcare and Life Sciences]<br>**Healthcare** <br>**Life Sciences** | <ul><li> 1: Personalization of Patient Care<li> 2: Proactive Health Management<li> 3: Patient Triangle Optimization<li> 4: Alerts and Diagnostics from Real Time Patient Data<li> 5: Disease Identification and Risk Stratification<li>6: Healthcare Provider Sentiment Analysis</ul>
[Travel and Hospitality]<br>**Travel & Logistics** <br>**Hospitality Services** | <ul><li> 1: Price Optimization, Dynamic Pricing<li> 2: Aircraft Scheduling<li> 3: Social Media Consumer Feedback and Interaction Analysis<li> 4: Customer Complaint Resolution<li> 5: Traffic Patterns and Congestion Management, Route Optimization</ul>
[Manufacturing]<br>**Manufacturing** | <ul><li> 1: Predictive Maintenance<li> 2: Demand Forecasting<li> 3: Process Optimization<li> 4: Telematics<li> 5: Warranty Analytics (Warranty reserve estimation)</ul>

- Some of other use cases could be described as follows:
  - Improving the aftermath management of an event such as earthquake or equivalent natural disaster
  - Preventing gang and gun violence using SMA (Social Media Analytics)
  - Applying Deep Learning and AI to detect wildfires and help prevent the same


The advantages of ML are useful where large dataset is available. Large scale deployments of ML is beneficial in terms of improved velocity and accuracy. It helps in understanding non-linearity of the data and generates a function mapping input to ouput from supervised learning standpoint. Lot of aspects around supervised, unsupervised and reinforced learning can be performed. This by and large ensures better profiling of customers to understand their needs. It helps serve customers better and reduce customer attrition.

# Quick Guideline points for Beginner and Intermediate levels

Level in Data and AI|Guideline or Checklist points
--------------------|-----------------------------
[Level 1]<br>**Beginner Level** | **Level 1: Beginner Stage**<ul><li>1: Academia background of Mathematics and Statistics<li>2: Exposure to Programming skills<li>2.1: Concepts of fundamentals in programming languages such as Python and R<li>2.2: Style aspect for Python and R - mentioned above as a suggestion<li>2.3: Readability - Has comments, indentation as per style guide<li>2.4: Modular - code is broken into small parts, functions, sub-routines as needed<li>2.5: Flow of control - code should perform what it is meant for<li>3: Understanding of Story telling<li>4: Understanding of Methodology to drive business problems to data problems<li>5: Understanding of Business KPIs and Drivers<li>6: Exposure to environment, tools and technologies at a high level<li>7: Exposure to Python or R<li>8: Data Visualization and EDA</ul>
[Level 2]<br>**Intermediate Level** | **Level 2: Intermediate Stage**<ul><li>1: Understanding of all that is required at a "Beginner Level"<li>2: Ability to formulate different techniques for a problem<li>3: GFamiliarity with Python and R with a grip on one of those strongly<li>4: Strong applied skills in EDA<li>5: Strong story telling and Data visualization<li>6: Machine Learning<li>7: Deep Learning</ul>


# Data Visualization and Storytelling
Below are some of references that can be referred for learning (but not exhaustive list by any means)

- [DV guidelines by Edward Tufte](https://www.edwardtufte.com/tufte/)
- [Storytelling with Data](http://www.storytellingwithdata.com/)
- [Information is Beautiful](https://informationisbeautiful.net/)
- [Junk Charts](https://junkcharts.typepad.com/)
- [The Atlas](https://www.theatlas.com/)
- [The Pudding](https://www.theatlas.com/)
- [Flowing Data](https://flowingdata.com/)
- [Visualising Data](https://www.visualisingdata.com/)

## Apache Superset - for Data exploration and visualization

Reference: https://github.com/apache/incubator-superset
Apache Superset (incubating) is a modern, enterprise-ready business intelligence web application

# Miscellaneous References

## Learning Reference for Probability and Stats

- Towardsdatascience
- Elitedatascience
- Khan Academy
- OpenIntro
- Exam Solutions
- Seeing Theory
- OLI
- Class Central
- Alison
- Guru99

## Sites / References to learn Python 

- [Python for Beginners - 1](https://www.python.org/about/gettingstarted/)
- [Python for Beginners - 2](https://www.pythonforbeginners.com/basics/)
- [Learn Python programming in 7 days, Guru99](https://www.guru99.com/python-tutorials.html)
- [Pythonspot](https://pythonspot.com/)
- [Code Academy](https://www.codecademy.com/catalog/language/python)
- [TutorialsPoint](https://www.tutorialspoint.com/)
- [The Python org](https://www.python.org/)
- [Interactive Python](https://www.interactivepython.org/)
- [Python Tutor](http://pythontutor.com/)
- [Awesome Python](https://pythonawesome.com/)
- [Awesome Python Github Reference](https://github.com/vinta/awesome-python)
- [Full Stack Python](https://www.fullstackpython.com/)
- [CheckiO](https://checkio.org/)

## Datasets For Exploration and Usage

- [Google Datasets](https://ai.google/tools/datasets/)
- [Data.world](https://data.world/)
- [Kaggle datasets](https://www.kaggle.com/datasets)
- [US Govertnment Open Datasets for usage](https://www.data.gov/)
- [FiveThirtyEight](https://fivethirtyeight.com/)
- [BuzzFeed](https://www.buzzfeed.com/)
- [Socrata OpenData](https://dev.socrata.com/data/)
- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets.php)
- [Reddit or R/datasets](https://www.reddit.com/r/datasets/comments/9oai7u/list_of_public_datasets/)
- [Quandl](https://www.quandl.com/)
- [Academic Torrents](http://academictorrents.com/)

## Computer Vision
Computer Vision is a sub branch of AI whose objective is to provide computers the powerful ability to understand their sorrounding by seeing the things more than hearing or feeling, just like humans. Kind of mimicing human ability to interpret by learning certain aspects.
Some applications of Computer Vision are as follows:

- Controlling processes
- Navigation
- Organizing set of information
- Automatic inspection
- Modeling objects or environments
- Detecting events
- Recognize objects
- Recognize actions
- Track objects in action

## NLP

- Key methods to look for: word2vec, ELMo, ULMFiT, GPT, BERT, RoBERTa, GloVe, InferSent, skip-thought

Topic  | Description | Remarks             |
-------|-------------|---------------------|
ELMo   |Embeddings from Language Models | Utilizes bi-directional LSTM for specific tasks to look at a whole sentence prior to encoding a word. ELMo's LSTM is trained on huge amount of text dataset |
ULMFiT |Universal Language Model Fine-Tuning method | Transfer learning method for NLP task and demonstrated techniques that are key to fine tuning language model |
GPT    |Generative Pre-training Transformer (OpenAI)| |
BERT   |Bi-directional Encoder Representations from Transformer | |
GloVe  |Global Vectors for word representation | Unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a text corpus, and the resulting representations showcase interesting linear substructures of the word vector space |

![plot of Compare view between BERT, GPT, ELMo](/figures/Compare_BERT_GPT_ELMo.png)

- [Unsupervised Cross-lingual representative learning](https://ruder.io/unsupervised-cross-lingual-learning/)
- [The State and Fate of linguistic diversity](https://arxiv.org/abs/2004.090950)
- Reference to Open Datsets could be as follows:
  - [HotspotQA dataset (Question answering dataset)](https://hotpotqa.github.io/)
  - [Amazon reviews dataset](https://snap.stanford.edu/data/web-Amazon.html)
  - [SMS spam collection dataset in English](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/)
  - [Recommender systems datasets (from various sites, reviews etc](https://cseweb.ucsd.edu/~jmcauley/datasets.html)
  - [UCI spambase dataset - for classifying emails as spam or non-spam](https://archive.ics.uci.edu/ml/datasets/Spambase)


## Experiments

### Part 1: R Programming with univariate and bivariate analysis
These are program components which are used for mentoring purposes

### Part 2: Time series Forecasting in R
These are program components which are used for mentoring purposes

### Predict Web Page Tags based on its content
Classification of Web page content is vital to many tasks in Web information retrieval such as maintaining Web
directories and focused crawling. The uncontrolled nature of Web content presents additional challenges to Web page
classification as compared to traditional text classification, however the interconnected nature of hypertext
also provides features that can assist the process.

Here the task is to classify the web pages to the respective classes it belongs to, in a single label classification
setup (Each webpage can belong to only 1 class).

Basically given the complete html and url, predict the tag a web page belongs to out of 9 predefined tags as given below:

* People profile
* Conferences/Congress
* Forums
* News article
* Clinical trials
* Publication
* Thesis
* Guidelines
* Others


## Reference GitHub links

Category / Area                         | URL / Links|
----------------------------------------|------------|
Awesome Deep Learning Reference         | https://github.com/ChristosChristofidis/awesome-deep-learning|
The Open Source Data Science Masters.   | https://github.com/datasciencemasters/go |
Conversational AI with Transfer Learning| https://github.com/huggingface/transfer-learning-conv-ai/blob/master/README.md|
The incomplete deep learning guide      | https://github.com/sannykim/deep-learning-guide|


## Other References for Reading

Applied Machine Learning videos reference:
https://www.youtube.com/playlist?list=PL_pVmAaAnxIQGzQS2oI3OWEPT-dpmwTfA

``` Disclaimer: Information represented here is based on my own experiences, learnings, readings and no way represent any firm's opinion, strategy etc or any individual's opinion or not intended for anything else other than self learning. ```
